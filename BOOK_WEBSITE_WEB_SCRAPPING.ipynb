{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***BOOK WEBSITE***"
      ],
      "metadata": {
        "id": "Fh2vnAwOy4V7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data(data,url):\n",
        "  soup = bs(data)\n",
        "  books = soup.find_all('article',class_='product_pod')\n",
        "\n",
        "  imgs =[]\n",
        "  titles = []\n",
        "  price = []\n",
        "  stock = []\n",
        "\n",
        "  for i in books:\n",
        "    imgs.append(i.find('img')['src'])\n",
        "    titles.append(i.find('a',title=True)['title'])\n",
        "    price.append(i.find('p',class_='price_color').text[2:])\n",
        "    stock.append(i.find('p',class_='instock availability').text.strip())\n",
        "\n",
        "  d = {'Images':imgs,'Book_Titles':titles,'Price':price,'Stock_Availability':stock}\n",
        "  df = pd.DataFrame(d)\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "wDSw5JbAy20f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_response(url):\n",
        "  response = requests.get(url)\n",
        "\n",
        "  try:\n",
        "    if response.status_code == 200:\n",
        "      df = extract_data(response.text,url)\n",
        "      return df\n",
        "  except:\n",
        "    print('Request Denied')"
      ],
      "metadata": {
        "id": "d66S7qbzy28p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup as bs\n",
        "\n",
        "for i in range(1,51):\n",
        "  url = (f'https://books.toscrape.com/catalogue/page-{i}.html')\n",
        "  df = check_response(url)\n",
        "  df.to_csv(f'Book{i}.csv')"
      ],
      "metadata": {
        "id": "N0F9WSP_y2_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxmQZKs_yydu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup as bs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CAR DEKHO***"
      ],
      "metadata": {
        "id": "TE5kpgf4zNBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrap_car_dekho(data):\n",
        "  cars = data.find_all('li',class_='gsc_col-xs-12 gsc_col-sm-6 gsc_col-md-12 gsc_col-lg-12')\n",
        "  car_name=[]\n",
        "  price=[]\n",
        "  fuel_type=[]\n",
        "  mileage=[]\n",
        "  drive_type=[]\n",
        "  engine_cc=[]\n",
        "  horse_power=[]\n",
        "  safety_star=[]\n",
        "\n",
        "  for i in cars:\n",
        "\n",
        "    #car_names\n",
        "    try:\n",
        "      car_name.append(i.find('h3').text)\n",
        "    except:\n",
        "      car_name.append(np.nan)\n",
        "\n",
        "    #price\n",
        "    try:\n",
        "      price.append(i.find('div',class_='price').text.split('*')[0][3:][:-6:])\n",
        "    except:\n",
        "      price.append(np.nan)\n",
        "\n",
        "    #fuel_type\n",
        "    try:\n",
        "      fuel_type.append(i.find_all(\"div\",class_='dotlist')[0].find_all('span')[0].text)\n",
        "    except:\n",
        "      fuel_type.append(np.nan)\n",
        "\n",
        "    #mileage\n",
        "    try:\n",
        "      mileage.append(i.find_all(\"div\",class_='dotlist')[0].find_all('span')[1].text[:-5])\n",
        "    except:\n",
        "      mileage.append(np.nan)\n",
        "\n",
        "    #drive_type\n",
        "    try:\n",
        "      drive_type.append(i.find_all(\"div\",class_='dotlist')[0].find_all('span')[2].text)\n",
        "    except:\n",
        "      drive_type.append(np.nan)\n",
        "\n",
        "    #engine_cc\n",
        "    try:\n",
        "      engine_cc.append(i.find_all(\"div\",class_='dotlist')[1].find_all('span')[0].text[:-3])\n",
        "    except:\n",
        "      engine_cc.append(np.nan)\n",
        "\n",
        "    #horse_power\n",
        "    try:\n",
        "      horse_power.append(i.find_all(\"div\",class_='dotlist')[1].find_all('span')[1].text[:-4])\n",
        "    except:\n",
        "      horse_power.append(np.nan)\n",
        "\n",
        "    #safety_star\n",
        "    try:\n",
        "      x = (i.find_all(\"div\",class_='dotlist')[1].find_all('span')[2].text)\n",
        "      if 'Star' in x:\n",
        "        safety_star.append(x[0])\n",
        "      else:\n",
        "        safety_star.append(np.nan)\n",
        "    except:\n",
        "      safety_star.append(np.nan)\n",
        "\n",
        "\n",
        "\n",
        "  d = {'Car_Name':car_name,'Price':price,'Fuel_Type':fuel_type,'Mileage':mileage,'Drive_Type':drive_type,'Engine_CC':engine_cc,'Horse_Power':horse_power,'Safety_Star':safety_star}\n",
        "\n",
        "  df = pd.DataFrame(d)\n",
        "  return df"
      ],
      "metadata": {
        "id": "QYkUhGnOy3CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(url):\n",
        "  res = requests.get(url,headers=headers)\n",
        "  try:\n",
        "    if res.status_code == 200:\n",
        "      df = scrap_car_dekho(bs(res.text))\n",
        "      df.to_csv(f\"{url.split('/')[-1].title()}.csv\")\n",
        "  except:\n",
        "    print('no')\n"
      ],
      "metadata": {
        "id": "kwsj_tNqzTY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.cardekho.com/newcars#brands'\n",
        "headers = {\"User-Agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'}\n",
        "\n",
        "response = requests.get(url,headers=headers)\n",
        "soup = bs(response.text)\n",
        "j = 0\n",
        "for i in soup.find_all('a',class_='BrIconNewCar'):\n",
        "  get_response(f\"https://www.cardekho.com{i['href']}\")"
      ],
      "metadata": {
        "id": "zAh3nCjErN3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AMbrKLGqw6UD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}